{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn.linear_model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import sklearn.linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearRegression():\n",
    "    \"\"\"\n",
    "    LSS-based linear regression model.\n",
    "    \"\"\"\n",
    "    def __init__(self, method='analytical', \n",
    "                       learning_rate=0.01, \n",
    "                       max_epochs=100, \n",
    "                       early_stopping_threshold=0.0003, \n",
    "                       iters_to_stop=5,\n",
    "                       regularization='none',\n",
    "                       C=1.):\n",
    "        \"\"\"\n",
    "        Initalizes new LinearResression model instance.\n",
    "        -----------\n",
    "        Parameters:\n",
    "        -----------\n",
    "            method: {'analytical', 'gd'}, default='analytical'\n",
    "                Algorithm that is selected to calculate linear model\n",
    "                weights and bias.\n",
    "                'analytical' - explicit formula (A^T*A)^-1*A^T*y\n",
    "                'gd' - gradient descent\n",
    "            learning_rate: float, default=0.01\n",
    "                If method='gd', then defines learning rate\n",
    "                for gradient descent, else ignored\n",
    "            max_epochs: int, default=100\n",
    "                For method='gd' defines upper boundary for\n",
    "                how many iterations will be done.\n",
    "            early_stopping_threshold: float, default=0.0003\n",
    "                For method='gd' defines what loss function value\n",
    "                difference between epoch and epoch+1 is considered as\n",
    "                idle iteration and convergence (criteria to stop).\n",
    "            iters_to_stop: int, default=5\n",
    "                For method='gd' defines how many idle iterations in a row\n",
    "                is required to stop further calculations.\n",
    "            regularization: {'none', 'l2', 'l1'}, default='none'\n",
    "                Type of regularization used in linear model.\n",
    "                'l1' works only for method='gd'\n",
    "            C: float, default=1.0\n",
    "                Regularization parameter. Ignored, if\n",
    "                regularization=none\n",
    "        \"\"\"\n",
    "        self.method = method\n",
    "        self.learning_rate = learning_rate\n",
    "        self.regularization = regularization\n",
    "        self.max_epochs = max_epochs\n",
    "        self.early_stopping_threshold = early_stopping_threshold\n",
    "        self.iters_to_stop = iters_to_stop\n",
    "        self.c = C\n",
    "        pass\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Fits X to y: calculates weights to minimize\n",
    "        MSE related to y.\n",
    "        Returns self\n",
    "        \"\"\"\n",
    "\n",
    "        if self.regularization == 'l1' and self.method != 'gd':\n",
    "            print('Warning! Regularization parameter is set to \\'l1\\' whilst method is not \\'gd\\'! Using method=\\'gd\\'...')\n",
    "            self.method = 'gd'\n",
    "        \n",
    "        if self.method == 'gd':\n",
    "            self.coef_ = np.zeros(X.shape[1])\n",
    "            self.bias = 0\n",
    "            a_ddx = np.zeros(X.shape[1])\n",
    "            b_ddx = 0\n",
    "\n",
    "            self.prev_error = 0\n",
    "            self.useless_iterations = 0\n",
    "\n",
    "            for ep in range(self.max_epochs):\n",
    "                y_pred = X @ self.coef_ + self.bias\n",
    "                error = y - y_pred.ravel()\n",
    "                # early stopping\n",
    "                if np.abs(error.mean()-self.prev_error) < self.early_stopping_threshold:\n",
    "                    if self.useless_iterations >= self.iters_to_stop:\n",
    "                        return self\n",
    "                    self.useless_iterations += 1\n",
    "                else:\n",
    "                    self.useless_iterations = 0\n",
    "                self.prev_error_mean = error.mean()\n",
    "                \n",
    "                for i in range(X.shape[1]):\n",
    "                    if self.regularization == 'l2':\n",
    "                        a_ddx[i] = -2 * (X[:,i] * error).mean() + 2*self.c*self.coef_[i]/len(X[:,i])\n",
    "                    if self.regularization == 'l1':\n",
    "                        a_ddx[i] = -2 * (X[:,i] * error).mean() + np.sign(self.coef_[i])*self.c/len(X[:,i])\n",
    "                    if self.regularization == 'none':\n",
    "                        a_ddx[i] = -2 * (X[:,i] * error).mean()\n",
    "                b_ddx = -2 * error.mean()\n",
    "                     \n",
    "                for i in range(X.shape[1]):\n",
    "                    self.coef_[i] -= self.learning_rate * a_ddx[i]\n",
    "                self.bias -= self.learning_rate * b_ddx\n",
    "            return self\n",
    "        if self.method == 'analytical':\n",
    "            ones = np.ones(shape=(X.shape[0], 1))\n",
    "            A = np.concatenate([ones, X], axis=1)\n",
    "            if self.regularization == 'none':\n",
    "                self.weights = np.linalg.inv(A.T @ A) @ A.T @ y\n",
    "                self.coef_ = self.weights[1:]\n",
    "                self.bias = self.weights[0]\n",
    "            if self.regularization == 'l2':\n",
    "                self.weights = np.linalg.inv(A.T @ A + self.c*np.eye(A.shape[1])) @ A.T @ y\n",
    "                self.coef_ = self.weights[1:]\n",
    "                self.bias = self.weights[0]            \n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predicts and returns outputs for X using formula:\n",
    "            ---------------\n",
    "            y_pred = Xw + b\n",
    "            ---------------\n",
    "            X - input data, 2-dimensional array \n",
    "            (samples x features).\n",
    "            w, b - vector of weights and bias scalar\n",
    "            calculated at fit() step.\n",
    "        \"\"\"\n",
    "        return X @ self.coef_ + self.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('iris.data')\n",
    "ohe = preprocessing.OneHotEncoder(sparse=False)\n",
    "ohe_iris_type = pd.get_dummies(data[['Species']])\n",
    "#df = data.iloc[:,:-1]\n",
    "df = pd.concat([data.iloc[:,:-1], ohe_iris_type.iloc[:,:-1]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ohe_iris_type.sum(axis=1).unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df\n",
    "X, y = df.loc[:,df.columns!='Sepal-width'], df['Sepal-width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sepal-length</th>\n",
       "      <th>Sepal-width</th>\n",
       "      <th>Petal-length</th>\n",
       "      <th>Petal-width</th>\n",
       "      <th>Species_Iris-setosa</th>\n",
       "      <th>Species_Iris-versicolor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>6.7</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>6.3</td>\n",
       "      <td>2.5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>6.5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>6.2</td>\n",
       "      <td>3.4</td>\n",
       "      <td>5.4</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>5.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.1</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sepal-length  Sepal-width  Petal-length  Petal-width  \\\n",
       "0             5.1          3.5           1.4          0.2   \n",
       "1             4.9          3.0           1.4          0.2   \n",
       "2             4.7          3.2           1.3          0.2   \n",
       "3             4.6          3.1           1.5          0.2   \n",
       "4             5.0          3.6           1.4          0.2   \n",
       "..            ...          ...           ...          ...   \n",
       "145           6.7          3.0           5.2          2.3   \n",
       "146           6.3          2.5           5.0          1.9   \n",
       "147           6.5          3.0           5.2          2.0   \n",
       "148           6.2          3.4           5.4          2.3   \n",
       "149           5.9          3.0           5.1          1.8   \n",
       "\n",
       "     Species_Iris-setosa  Species_Iris-versicolor  \n",
       "0                      1                        0  \n",
       "1                      1                        0  \n",
       "2                      1                        0  \n",
       "3                      1                        0  \n",
       "4                      1                        0  \n",
       "..                   ...                      ...  \n",
       "145                    0                        0  \n",
       "146                    0                        0  \n",
       "147                    0                        0  \n",
       "148                    0                        0  \n",
       "149                    0                        0  \n",
       "\n",
       "[150 rows x 6 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning! Regularization parameter is set to 'l1' whilst method is not 'gd'! Using method='gd'...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.08259287873485013"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "linear = LinearRegression(regularization='l1')\n",
    "linear.fit(X_train.values, y_train.values)\n",
    "y_pred = linear.predict(X_test.values)\n",
    "mean_squared_error(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 5)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "nfolds_list = [10]\n",
    "regularizations = ['none', 'l2', 'l1']\n",
    "creators = ['me', 'sklearn']\n",
    "methods = ['analytical', 'gd']\n",
    "\n",
    "stats = pd.DataFrame(columns=[\n",
    "    'creator', 'method', 'nfolds', 'regularization', 'execution_time', 'weights', 'error'\n",
    "    ])\n",
    "\n",
    "skip_iteration = False\n",
    "\n",
    "for nfolds in nfolds_list:\n",
    "    for method in methods:\n",
    "        for creator in creators:\n",
    "            for regularization in regularizations:\n",
    "                exec_time = 0\n",
    "                error = 0\n",
    "                weights = np.zeros(X.shape[1])   \n",
    "                for i in range(nfolds):\n",
    "                    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "                    start_time = time.time()\n",
    "                    if creator == 'me':\n",
    "                        if regularization == 'l1' and method == 'analytical':\n",
    "                            skip_iteration = True\n",
    "                            break\n",
    "                        linear = LinearRegression(regularization=regularization, method=method)\n",
    "                    if creator == 'sklearn':\n",
    "                        if method == 'analytical':\n",
    "                            if regularization == 'l2':\n",
    "                                linear = sklearn.linear_model.Ridge(solver='cholesky')\n",
    "                            if regularization == 'l1':\n",
    "                                skip_iteration = True\n",
    "                                break\n",
    "                            if regularization == 'none':\n",
    "                                linear = sklearn.linear_model.LinearRegression()\n",
    "                        if method == 'gd':\n",
    "                            if regularization == 'none':\n",
    "                                skip_iteration = True\n",
    "                                break\n",
    "                            linear = sklearn.linear_model.SGDRegressor(penalty=regularization)\n",
    "                    linear.fit(X_train.values, y_train.values)\n",
    "                    y_pred = linear.predict(X_test.values)\n",
    "                    error += mean_squared_error(y_test, y_pred)\n",
    "                    weights += linear.coef_\n",
    "                        \n",
    "                    exec_time += time.time() - start_time\n",
    "\n",
    "                if skip_iteration:\n",
    "                    skip_iteration = False\n",
    "                    continue\n",
    "\n",
    "                exec_time /= nfolds\n",
    "                error /= nfolds\n",
    "                weights /= nfolds\n",
    "\n",
    "                new_model_stats_row = pd.Series({\n",
    "                                    'nfolds': nfolds, \n",
    "                                    'weights': weights, \n",
    "                                    'execution_time': exec_time,\n",
    "                                    'error': error,\n",
    "                                    'creator': creator,\n",
    "                                    'regularization': regularization,\n",
    "                                    'method': method\n",
    "                                    })\n",
    "                stats = stats.append(new_model_stats_row, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator</th>\n",
       "      <th>method</th>\n",
       "      <th>nfolds</th>\n",
       "      <th>regularization</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>weights</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>me</td>\n",
       "      <td>analytical</td>\n",
       "      <td>10</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000694</td>\n",
       "      <td>[0.3694393061279143, -0.1620296732017569, 0.70...</td>\n",
       "      <td>0.087943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sklearn</td>\n",
       "      <td>analytical</td>\n",
       "      <td>10</td>\n",
       "      <td>none</td>\n",
       "      <td>0.000598</td>\n",
       "      <td>[0.36943930612789744, -0.16202967320180092, 0....</td>\n",
       "      <td>0.087943</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   creator      method nfolds regularization  execution_time  \\\n",
       "0       me  analytical     10           none        0.000694   \n",
       "2  sklearn  analytical     10           none        0.000598   \n",
       "\n",
       "                                             weights     error  \n",
       "0  [0.3694393061279143, -0.1620296732017569, 0.70...  0.087943  \n",
       "2  [0.36943930612789744, -0.16202967320180092, 0....  0.087943  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats[(stats['method'] == 'analytical') & (stats['regularization'] == 'none')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both mine and sklearn's solution result stats turned out to be pretty same if no regulaziration and gradient descent are asked. The reason is that the formula used is the same. \n",
    "\n",
    "Though I assume that sklearn have some embedded tools to check whether it's important to check features' VIF factors. So sklearn's solution requires more time when it comes to build model when there's columns linear relation but returns much more relevant and stable result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator</th>\n",
       "      <th>method</th>\n",
       "      <th>nfolds</th>\n",
       "      <th>regularization</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>weights</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>me</td>\n",
       "      <td>analytical</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>[0.492680221510465, -0.2808919092799675, 0.470...</td>\n",
       "      <td>0.080067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sklearn</td>\n",
       "      <td>analytical</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.000604</td>\n",
       "      <td>[0.4331726360595022, -0.2821255289525397, 0.44...</td>\n",
       "      <td>0.077549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   creator      method nfolds regularization  execution_time  \\\n",
       "1       me  analytical     10             l2        0.000200   \n",
       "3  sklearn  analytical     10             l2        0.000604   \n",
       "\n",
       "                                             weights     error  \n",
       "1  [0.492680221510465, -0.2808919092799675, 0.470...  0.080067  \n",
       "3  [0.4331726360595022, -0.2821255289525397, 0.44...  0.077549  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats[(stats['method'] == 'analytical') & (stats['regularization'] == 'l2')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For some reason sklearn's implementation works twice longer than mine and has error that is slightly lower than my model's error. The point is that sklearn provides different ways to calculate weights, including SVD-decomposition, different forms of gradient descent, but not analytical soultion I provided. It chooses it automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator</th>\n",
       "      <th>method</th>\n",
       "      <th>nfolds</th>\n",
       "      <th>regularization</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>weights</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>me</td>\n",
       "      <td>gd</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.006189</td>\n",
       "      <td>[0.6408663262179466, -0.21948945559413718, -0....</td>\n",
       "      <td>0.082542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sklearn</td>\n",
       "      <td>gd</td>\n",
       "      <td>10</td>\n",
       "      <td>l2</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>[0.6443986397300759, -0.24265935596317117, -0....</td>\n",
       "      <td>0.081597</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   creator method nfolds regularization  execution_time  \\\n",
       "5       me     gd     10             l2        0.006189   \n",
       "7  sklearn     gd     10             l2        0.000100   \n",
       "\n",
       "                                             weights     error  \n",
       "5  [0.6408663262179466, -0.21948945559413718, -0....  0.082542  \n",
       "7  [0.6443986397300759, -0.24265935596317117, -0....  0.081597  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats[(stats['method'] == 'gd') & (stats['regularization'] == 'l2')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My solution took significantly more time that sklearn's one, but errors don't differ this much. The thing is that I might have tuned standard learning rate and tolerance value not in the optimal way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>creator</th>\n",
       "      <th>method</th>\n",
       "      <th>nfolds</th>\n",
       "      <th>regularization</th>\n",
       "      <th>execution_time</th>\n",
       "      <th>weights</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>me</td>\n",
       "      <td>gd</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.007048</td>\n",
       "      <td>[0.6407812408399931, -0.22062606881463803, -0....</td>\n",
       "      <td>0.082593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>sklearn</td>\n",
       "      <td>gd</td>\n",
       "      <td>10</td>\n",
       "      <td>l1</td>\n",
       "      <td>0.000997</td>\n",
       "      <td>[0.644388664104617, -0.24130397134819964, -0.0...</td>\n",
       "      <td>0.084150</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   creator method nfolds regularization  execution_time  \\\n",
       "6       me     gd     10             l1        0.007048   \n",
       "8  sklearn     gd     10             l1        0.000997   \n",
       "\n",
       "                                             weights     error  \n",
       "6  [0.6407812408399931, -0.22062606881463803, -0....  0.082593  \n",
       "8  [0.644388664104617, -0.24130397134819964, -0.0...  0.084150  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stats[(stats['method'] == 'gd') & (stats['regularization'] == 'l1')]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same thing is about l1-regularization - I think I should tune standard parameters more accurately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# по фолдам: считаем время, веса, ошибки, параметр алгоритма задачи\n",
    "# sql\n",
    "# numpy\n",
    "# + регуляризация\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ml\n",
    "# создать репозиторий, оформить в виде класса регрессию\n",
    "# сделать норм таблицы шоб понятно было + анализ (быстрее, наверное потому что ...)\n",
    "# --------------------------------\n",
    "# python лутс глава 1 читать\n",
    "# --------------------------------\n",
    "# numpy матрицу доделываю\n",
    "# ----------------------------"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8f0fa1c098f607fd5c5f44bcea68efad758ed2eacaa4c1ac80ae4713d116068f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
